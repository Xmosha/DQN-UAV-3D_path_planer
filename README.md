# DQN-based-UAV-3D_path_planer
Realization of UAV's Track Planning in 3D Urban Environment Based on Reinforcement Learning Algorithm(DQN)

## 环境需求
python 3.7

pytorch(cuda)
## 模型简介
采用课程学习方式对无人机智能体进行训练，利用设置好的不同难度的课程对智能体进行梯度训练，能让智能体更快地获取决策经验。由于训练初期缺乏决策经验，需要随机选择行为对环境进行试探，本文设置随机试探周期为1000，周期内采用ε-贪心策略选择智能体行为，周期内贪心概率从1逐渐递减到0.01。1000周期后贪心概率保持在0.01。在一个周期的训练场景中随机生成15个无人机对象，当所有无人机进入终止状态（电量耗尽、坠毁、到达目标点、超过最大步长）后进入下一个周期的训练，当80%以上的无人机能够到达目标点时进入下一难度等级的训练。
经过13万周期、19小时的迭代训练，最终无人机智能体能够在难度5的环境中以97%的任务完成率安全到达目标点，训练模型的累积得分情况如5.1所示。由图5.1可知，模型在随着训练轮次的增加每1000轮次的平均得分逐渐增加，模型在100k回合后分数开始收敛，模型趋于稳定。
![avatar](航迹图.jpg)
## 训练参数设置
## 无人机状态空间
## 无人机动作空间
## 奖励函数设置
