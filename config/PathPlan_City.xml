<!DOCTYPE root [
  <!ENTITY external SYSTEM "buidings.xml">
]>
<simulator>
    <env>
        <Env_Type>PathPlan_City</Env_Type>
        <len>500</len>
        <width>500</width>
        <h>1</h>
        <eps>0.1</eps>
        <Is_AC>0</Is_AC>
        <Is_FL>1</Is_FL>
        <Is_On_Policy>0</Is_On_Policy>
        <FL_Loop>3</FL_Loop>
        <print_loop>2</print_loop>
        <num_UAV>20</num_UAV>
        <Agent>
            <Agent_Type>UAV</Agent_Type>
            <name>UAV_</name>
            <update_function_name>update_PathPlan</update_function_name>
            <state_function_name>state_PathPlan</state_function_name>
            <position>
                <x>250</x>
                <y>250</y>
                <z>75</z>
            </position>
            <Max_V>20</Max_V>
            <R>50</R>
            <R_comm>75</R_comm>
            <Acceration>5</Acceration> 
            <Max_Step>150</Max_Step>
            <f_max>5</f_max>
            <DFRL_param>
                <update_rate>0.05</update_rate>
                <Top_G>20</Top_G>
            </DFRL_param>
            <Power_param>
                <Fly_power>
                    <P_i>89</P_i>
                    <v_0>4.05</v_0>
                    <d_0>0.6</d_0>
                    <rho>1.225</rho>
                    <s>0.05</s>
                    <A>0.5</A>
                    <P_b>79</P_b>
                    <F_b>120</F_b>
                </Fly_power>
                <Communication_power>3</Communication_power>
            </Power_param>
            <UEs_param>
                <Agent_Type>UE_experience</Agent_Type>
                <UES_num>100</UES_num>
                <step_len>2</step_len>
                <D_max>1000</D_max>
                <D>10</D>                    
                <F>0.05</F>
                <B>1</B>
                <g_0>0.000142</g_0>
                <G_0>2.228</G_0>
                <theta_2>-90</theta_2>
                <P_tr>0.1</P_tr>
            </UEs_param>
            <DSNs_param>
                <DSN_num>6</DSN_num>
                <step_skill_max>2</step_skill_max>                    
                <DSN_gamma>1</DSN_gamma>
            </DSNs_param>

            <Trainer>
                <Trainer_Type>SAC_Trainer</Trainer_Type>
                <Is_Train>1</Is_Train>
                <actor>
                    <NetWork>PolicyNet_SAC</NetWork>
                    <h>1</h>
                    <w>87</w> 
                    <channel>1</channel>
                    <hiden_dim>128</hiden_dim>
                    <output>6</output>
                    <lr>0.0005</lr>
                </actor>
                <critic>
                    <NetWork>QValueNet_SAC</NetWork>
                    <h>1</h>
                    <w>87</w>
                    <channel>1</channel>
                    <hiden_dim>128</hiden_dim>
                    <output>6</output>
                    <lr>0.0005</lr>
                </critic>
                <SAC_param>
                    <IS_Continuous>0</IS_Continuous>
                    <alpha_lr>0.0001</alpha_lr>
                    <target_entropy>-1</target_entropy>
                    <gamma>0.98</gamma>
                    <tau>0.05</tau>
                </SAC_param>                 
                <replay_size>10000</replay_size>
                <LEARNING_RATE>0.005</LEARNING_RATE>
                <Batch_Size>128</Batch_Size>
                <max_epoch>10000</max_epoch>
                <save_loop>10000</save_loop>
            </Trainer>
        </Agent>
        &buidings
    </env>
    
    <record_epo>10</record_epo>
    <num_episodes>500</num_episodes> 
    <max_eps_episode>1</max_eps_episode>
    <min_eps>0.1</min_eps>
    <TARGET_UPDATE>3</TARGET_UPDATE>
</simulator>